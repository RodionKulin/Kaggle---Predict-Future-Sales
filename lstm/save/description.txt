Description: Basic LSTM model. Predict one day at a time.Score on 90 days prediction: 151577

Epoch, Loss, Validation Loss:
Epoch 1 - 1.2375 15.4107

Train duration: 0:00:14.184990
Train rows number: 730000
Validation rows number: 183000

Model summary:
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 1024)              4456448   
_________________________________________________________________
dense (Dense)                (None, 512)               524800    
_________________________________________________________________
dense_1 (Dense)              (None, 128)               65664     
_________________________________________________________________
dense_2 (Dense)              (None, 32)                4128      
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 33        
=================================================================
Total params: 5,051,073
Trainable params: 5,051,073
Non-trainable params: 0
_________________________________________________________________

Model parameters:
do_validation=True
verbose=1
steps=1
metrics=['loss', 'val_loss']
epochs=1
Batch size=8
Steps per training epoch=1
Steps per validation=1
Input length=50
Days to predict=90


Sanity check prediction:
    predicted  actual
0      -97.41    18.0
1     -111.24     5.0
2     -126.40    14.0
3     -142.18    12.0
4     -158.01    26.0
5     -173.50    15.0
6     -188.34    16.0
7     -202.33    28.0
8     -215.33    12.0
9     -227.26    20.0
10    -238.11    16.0
11    -247.87    23.0
12    -256.59    22.0
13    -264.33    13.0
14    -271.15    25.0
15    -277.14    11.0
16    -282.38    14.0
17    -286.94    17.0
18    -290.91    16.0
19    -294.35    18.0
20    -297.32    15.0
21    -299.89    21.0
22    -302.10    14.0
23    -304.01    24.0
24    -305.64    22.0
25    -307.04    23.0
26    -308.24    17.0
27    -309.26    20.0
28    -310.13    25.0
29    -310.87    14.0
30    -311.48    13.0
31    -312.00    23.0
32    -312.43    18.0
33    -312.79    19.0
34    -313.08    20.0
35    -313.31    17.0
36    -313.49    21.0
37    -313.62    13.0
38    -313.72    12.0
39    -313.78    22.0
40    -313.82    13.0
41    -313.83    26.0
42    -313.81    21.0
43    -313.78    17.0
44    -313.73    22.0
45    -313.66    21.0
46    -313.58    25.0
47    -313.49    25.0
48    -313.39    23.0
49    -313.28    20.0
50    -313.16    19.0
51    -313.04    21.0
52    -312.91    17.0
53    -312.77    25.0
54    -312.63    15.0
55    -312.48    20.0
56    -312.33    32.0
57    -312.18    13.0
58    -312.02    21.0
59    -311.86    19.0
60    -311.70    26.0
61    -311.54    27.0
62    -311.37    19.0
63    -311.20    22.0
64    -311.04    17.0
65    -310.87    26.0
66    -310.69    22.0
67    -310.52    26.0
68    -310.35    25.0
69    -310.17    32.0
70    -310.00    33.0
71    -309.82    15.0
72    -309.65    21.0
73    -309.47    29.0
74    -309.29    19.0
75    -309.11    28.0
76    -308.93    34.0
77    -308.75    31.0
78    -308.57    24.0
79    -308.39    32.0
80    -308.21    17.0
81    -308.03    18.0
82    -307.85    26.0
83    -307.67    25.0
84    -307.48    32.0
85    -307.30    17.0
86    -307.12    24.0
87    -306.93    16.0
88    -306.75    32.0
89    -306.56    35.0